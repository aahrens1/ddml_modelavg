-------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /cluster/home/kahrens/ddml_applied/GWG/Output/GWG_53356_3.txt
  log type:  text
 opened on:  10 Dec 2023, 19:14:53

. 
. which ddml
/cluster/home/kahrens/ado/plus/d/ddml.ado
*! ddml v1.4.3
*! last edited: 17aug2023
*! authors: aa/ms

. which pystacked
/cluster/home/kahrens/ado/plus/p/pystacked.ado
*! pystacked v0.7.5
*! last edited: 7aug2023
*! authors: aa/ms

. 
. set seed `seed'

. local folder out_`seed'

. 
. use "../Data/gender_gap_ML_processed", clear

. 
. cap mkdir `folder'

. 
. *****************************************************************************
> ***
. ***  controls
. *****************************************************************************
> ***
. 
. // create squared age and tenure here
. gen age_r2 = age_r^2

. gen tenure2 = tenure^2
(2 missing values generated)

. 
. // no base categories
. global continuous                                                            
>                                                            ///
>         age_r                                                                
>                                                                    /// no mis
> sing
>         yrsqual         /* years of education (derived) */                   
>                                    /// 355 missing
>         /// leavedu             /* age when left education (derived) */      
>                            /// 1,081 missing
>         pvlit1          /* literacy score: plausible value 1 (also 2-10 avail
> ) */       /// no missing
>         pvnum1          /* numeracy score: plausible value 1 (also 2-10 avail
> ) */       /// no missing
>         tenure          /* tenure = years in work for current employer */    
>                    /// 2 missing
>                                                                              
>                                                                            //

. // add second order terms here
. global continuous $continuous age_r2 tenure2

. 
. global discrete0                                                             
>                                                            ///             
>         b_q01a          /* education, highest level attained */              
>                            /// no missing
>         b_q01b          /* area of study */                                  
>                                                    /// 434 missing
>         d_q06c          /* part of a larger organization */                  
>                                    /// 13 missing
>         d_q08a          /* management position */                            
>                                            /// no missing
>         d_q09           /* type of contract */                               
>                                            /// 12 missing
>         d_q10_t1        /* hours per week at this job or business */         
>                    /// 1 missing
>         d_q14           /* job satisfaction */                               
>                                            /// 1 missing
>         i_q08           /* health status */                                  
>                                                    /// 2 missing
>         j_q02a          /* living with a partner */                          
>                                            /// 899 missing
>         j_q03d1_c       /* age of youngest child */                          
>                                            /// 2,718 missing
>         j_q04c1_c       /* immigration: age */                               
>                                            /// 4,375 missing
>         j_q06b          /* mother's highest level of educ */                 
>                            /// 445 missing
>         j_q07b          /* father's highest level of educ */                 
>                            /// 515 missing
>         j_q03b          /* number of children*/                              
>                                            /// 1,856 missing
>         impar           /* immigration: parents */                           
>                                            /// 21 missing
>         imgen           /* immigration: generation */                        
>                                    /// 344 missing
>         nfe12jr         /* informal job-related educ in prev 12 months */    
>                    /// 116 missing
>         nfe12njr        /* informal non-job-related educ in prev 12 months */
>            /// 116 missing
>                                                                              
>                                                                            //
>                                                                              
>                                                          

. global personality                                                           
>                                                            ///
>         i_q04b          /* Learning strategies, Relate new ideas into real li
> fe */      /// 16 missing
>         i_q04d          /* Learning strategies, Like learning new things */  
>                    /// no missing
>         i_q04h          /* Learning strategies, Attribute something new */   
>                    /// 10 missing
>         i_q04j          /* Learning strategies, Deal with difficult things */
>            /// no missing
>         i_q04l          /* Learning strategies, Fit different ideas together 
> */         /// 5 missing
>         i_q04m          /* Learning strategies, Looking for additional info *
> /          /// 1 missing
>         i_q05f          /* Cultural engagement, Voluntary non-profit work */ 
>            /// no missing
>         i_q06a          /* Political efficacy, No influence on the government
>  */        /// 14 missing
>         i_q07a          /* Social trust, Trust only few people */            
>                            /// 4 missing
>         i_q07b          /* Social trust, Other people take advantage of you *
> /          /// 6 missing
>                                                                              
>                                                                            //

. global discrete $discrete0                                                   
>                                                    ///
>         new_reg_tl2     /* geographical region */                            
>                                            /// 2 missing
>         new_isco1c      /* occupation */                                     
>                                                    /// no missing
>         new_isic1c      /* industry */                                       
>                                                    // no missing

. 
. global X_simple                                                         ///
>         i.(b_q01a d_q10_t1 j_q03b)                              ///
>         c.($continuous)

. 
. global X_fullinteracted                                         ///
>         i.($discrete0 )                                                 ///
>         i.new_isco1c#i.new_isic1c#i.new_reg_tl2 ///
>         c.($continuous)                  

.         
. global X_cont                                                           ///
>         c.($continuous)##i.($discrete)

. 
. global X_expanded                                                       ///
>         i.($discrete)                                                   ///
>         c.($continuous)                                                 ///
>         c.age_r#i.($discrete)                                   ///
>         c.tenure#i.($discrete)

. 
.         
. 
. *****************************************************************************
> ***
. ***  estimation sample
. *****************************************************************************
> ***
. 
. gen byte touse=1

. markout touse lnearn $X_expanded

. keep if touse
(53 observations deleted)

. 
. 
. *****************************************************************************
> ***
. ***  learners
. *****************************************************************************
> ***
. 
. global cores = 5

. 
. global rf1 min_samples_leaf(1)  max_features(sqrt) n_estimators(500)

. global rf2 min_samples_leaf(50)  max_features(sqrt) n_estimators(500)

. global rf3 min_samples_leaf(100)  max_features(sqrt) n_estimators(500)

. global grad1 n_estimators(500) n_iter_no_change(10)  

. global grad2 n_estimators(500)  

. global nnet1 hidden_layer_sizes(40 20 1 20 50) early_stopping 

. global nnet2 hidden_layer_sizes(30 30 30) early_stopping  

. 
. global pystring_reg0                                                         
>    || ///
>                                         m(ols)                               
>                            || ///
>                                         m(ols) xvars($X_simple)              
>            || ///
>                                         m(lassocv)                           
>                            || ///
>                                         m(ridgecv)                           
>                            || ///
>                                         m(lassocv)      xvars($X_cont)       
>            || ///
>                                         m(ridgecv)      xvars($X_cont)       
>            || ///
>                                         m(rf) opt($rf1)                      
>                    || ///
>                                         m(rf) opt($rf2)                      
>                    || ///
>                                         m(rf) opt($rf3)                      
>                    || ///
>                                         m(gradboost) opt($grad1)             
>            || ///
>                                         m(gradboost) opt($grad2)             
>            || ///
>                                         m(nnet) opt($nnet1)                  
>            || ///
>                                         m(nnet) opt($nnet2)                  
>            || //

. 
. global pystring_reg  $pystring_reg0 , type(reg) njobs($cores) 

.  
. global pystring_class0                                                       
>            || ///
>                                         m(logit)                             
>                            || ///
>                                         m(logit) xvars($X_simple)            
>            || ///
>                                         m(lassocv)                           
>                            || ///
>                                         m(ridgecv)                           
>                            || ///
>                                         m(lassocv)      xvars($X_cont)       
>            || ///
>                                         m(ridgecv)      xvars($X_cont)       
>            || ///
>                                         m(rf) opt($rf1)                      
>                    || ///
>                                         m(rf) opt($rf2)                      
>                    || ///
>                                         m(rf) opt($rf3)                      
>                    || ///
>                                         m(gradboost) opt($grad1)             
>            || ///
>                                         m(gradboost) opt($grad2)             
>            || ///
>                                         m(nnet) opt($nnet1)                  
>            || ///
>                                         m(nnet) opt($nnet2)                  
>            || //                   

.                                 
. global pystring_class $pystring_class0 , type(class) njobs($cores)

.                                         
. global R =1  

. global K=10 

. global L =13

.         
. *****************************************************************************
> *  
. *** ddml: estimation                                                         
>                                               ***
. *****************************************************************************
> *
. 
. if (`estimator'==1) {
. 
.         ddml init partial,  reps($R) kfolds($K)
.         ddml E[Y|X]: pystacked lnearn $X_expanded $pystring_reg
.         ddml E[D|X]: pystacked gender_r $X_expanded $pystring_reg
.         ddml crossfit, shortstack poolstack
.         ddml estimate, robust
.         
.         foreach mat in lnearn_mse gender_r_mse {
  2.                         ddml extract, show(mse)
  3.                         mat `mat' = r(`mat')
  4.                         mat list `mat'
  5.                                 preserve
  6.                                 svmat `mat'
  7.                                 keep `mat'*
  8.                                 keep if _n<=$L
  9.                                 gen stack_type = "conventional" if _n==1
 10.                                 replace stack_type = "pooled" if _n==2
 11.                                 replace stack_type = "short" if _n==3
 12.                                 gen model = "plm"
 13.                                 list if _n<=$L
 14.                                 save `folder'/`mat'_plm_mse, replace
 15.                                 restore 
 16.         }       
. 
.         cap drop mse_*
.         foreach var of varlist Y1_* {
  2.                  cap drop sqerr_`var'
  3.                  gen double sqerr_`var'=(lnearn-`var')^2
  4.                  sum sqerr_`var', meanonly
  5.                  gen double mse_`var'=r(mean) if _n ==1 
  6.         }
.         foreach var of varlist D1_* {
  2.                  cap drop sqerr_`var'
  3.                  gen double sqerr_`var'=(gender_r-`var')^2
  4.                  sum sqerr_`var', meanonly
  5.                  gen double mse_`var'=r(mean) if _n ==1 
  6.         }
.         preserve
.                 keep mse_*
.                 keep if _n==1
.                 save `folder'/plm_mse, replace
.         restore
.         cap drop mse_*
. 
.         ** initialize results file
.         regsave gender_r using `folder'/results.dta, ci addlabel(model,partia
> l,seed,`seed',final,init,learner,-99) replace
. 
.         foreach final in nnls1 singlebest ols avg {
  2. 
.                 ddml estimate, robust finalest(`final')
  3.         
.                         // regular stacking results
.                         ddml estimate, mname(m0) spec(st) replay  
  4.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,partial,seed,`seed',final,`final',learner,-1) append
  5.                         
.                         // shortstacking results
.                         ddml estimate, mname(m0) spec(ss) replay 
  6.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,partial,seed,`seed',final,`final',learner,-2) append
  7.                         
.                         // poolstacking results
.                         ddml estimate, mname(m0) spec(ps) replay  
  8.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,partial,seed,`seed',final,`final',learner,-3) append     
  9.                 
.                         // pystacked weights
.                         ddml extract, show(stweights)   
 10.                         foreach mat in Y1_pystacked_w_mn D1_pystacked_w_mn
>  {
 11.                                         ddml extract, show(stweights)   
 12.                                         mat `mat' = r(`mat')
 13.                                         mat list `mat'
 14.                                                 preserve
 15.                                                 svmat `mat'
 16.                                                 keep `mat'*
 17.                                                 list if _n<=4
 18.                                                 save `folder'/`mat'_`final
> '_regular, replace
 19.                                                 restore
 20.                         }       
 21.                         // shortstacked weights
.                         ddml extract, show(ssweights)
 22.                         foreach mat in Y_lnearn_ss D_gender_r_ss {
 23.                                         qui ddml extract, show(ssweights)
 24.                                         mat `mat' = r(`mat')
 25.                                         mat list `mat'
 26.                                                 preserve
 27.                                                 svmat `mat'
 28.                                                 keep `mat'*
 29.                                                 list if _n<=4
 30.                                                 save `folder'/`mat'_`final
> '_short, replace
 31.                                                 restore
 32.                         }       
 33.                         // poolstacked weights
. 
.                         foreach mat in Y_lnearn_ps D_gender_r_ps {
 34.                                         qui ddml extract, show(psweights)
 35.                                         mat `mat' = r(`mat')
 36.                                         mat list `mat'
 37.                                                 preserve
 38.                                                 svmat `mat'
 39.                                                 keep `mat'*
 40.                                                 list if _n<=4
 41.                                                 save `folder'/`mat'_`final
> '_pooled, replace
 42.                                                 restore
 43.                         }       
 44.         
.         }
. 
.         forvalues i = 1(1)$L {
  2.                         ddml estimate, y(Y1_pystacked_L`i'_1) ///
>                                                         d(D1_pystacked_L`i'_1
> ) robust
  3.                         regsave gender_r using `folder'/results.dta, ci //
> /
>                                                 addlabel(model,partial,seed,`
> seed',final,indiv,learner,`i') ///
>                                                 append
  4.         }
. 
. }

.         
. *****************************************************************************
> *  
. *** interactive: estimation                                                  
>                                       ***
. *****************************************************************************
> *
.         
. if (`estimator'==2) {   
. 
.         ddml init interactive, kfolds($K) reps($R)
.         ddml E[Y|X,D]: pystacked lnearn $X_expanded $pystring_reg
.         ddml E[D|X]: pystacked gender_r $X_expanded $pystring_class
.         ddml crossfit, shortstack poolstack
.         ddml estimate, robust atet
. 
.         cap drop mse_*
.         foreach var of varlist Y1_pystacked0* {
  2.                  cap drop sqerr_`var'
  3.                  gen double sqerr_`var'=(lnearn-`var')^2 if gender_r==0
  4.                  sum sqerr_`var' if gender_r==0, meanonly
  5.                  gen double mse_`var'=r(mean) if _n ==1 
  6.         }
.         foreach var of varlist Y1_pystacked1* {
  2.                  cap drop sqerr_`var'
  3.                  gen double sqerr_`var'=(lnearn-`var')^2 if gender_r==1
  4.                  sum sqerr_`var' if gender_r==1, meanonly
  5.                  gen double mse_`var'=r(mean) if _n ==1 
  6.         }
.         foreach var of varlist D1_* {
  2.                  cap drop sqerr_`var'
  3.                  gen double sqerr_`var'=(gender_r-`var')^2
  4.                  sum sqerr_`var', meanonly
  5.                  gen double mse_`var'=r(mean) if _n ==1 
  6.         }
.         preserve
.                 keep mse_*
.                 keep if _n==1
.                 save `folder'/inter_mse, replace
.         restore
.         cap drop mse_*
.         
.         local mat gender_r_mse
.                         ddml extract, show(mse)
.                         mat `mat' = r(`mat')
.                         mat list `mat'
.                                 preserve
.                                 svmat `mat'
.                                 keep `mat'*
.                                 keep if _n<=$L
.                                 gen stack_type = "conventional" if _n==1
.                                 replace stack_type = "pooled" if _n==2
.                                 replace stack_type = "short" if _n==3
.                                 gen model = "interactive"
.                                 list if _n<=$L
.                                 save `folder'/`mat'_inter_gender_mse, replace
.                                 restore 
.                                 
.         local mat lnearn_mse
.                         ddml extract, show(mse)
.                         mat `mat' = r(`mat')
.                         mat list `mat'
.                                 preserve
.                                 svmat `mat'
.                                 keep `mat'*
.                                 keep if _n<=(2*$L)
.                                 gen stack_type = "conventional" if _n<=2
.                                 replace stack_type = "pooled" if _n>=3 & _n<=
> 4
.                                 replace stack_type = "short" if _n>4
.                                 gen model = "interactive"
.                                 list if _n<=(2*$L)
.                                 save `folder'/`mat'_inter_lnearn_mse, replace
.                                 restore 
.         
.         foreach final in nnls1 singlebest ols avg {
  2. 
.                 ddml estimate, robust finalest(`final') atet
  3.         
.                         // regular stacking results
.                         ddml estimate, mname(m0) spec(st) replay atet
  4.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,interactive,seed,`seed',final,`final',learner,-1) append
  5.                         
.                         // shortstacking results
.                         ddml estimate, mname(m0) spec(ss) replay atet
  6.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,interactive,seed,`seed',final,`final',learner,-2) append
  7.                         
.                         // poolstacking results
.                         ddml estimate, mname(m0) spec(ps) replay atet
  8.                         regsave gender_r using `folder'/results.dta, ci ad
> dlabel(model,interactive,seed,`seed',final,`final',learner,-3) append
  9.                 
.                         // pystacked weights
.                         ddml extract, show(stweights)
 10.                         foreach mat in Y1_pystacked_w_mn D1_pystacked_w_mn
>  {
 11.                                         ddml extract, show(stweights)
 12.                                         mat `mat' = r(`mat')
 13.                                         mat list `mat'
 14.                                                 preserve
 15.                                                 svmat `mat'
 16.                                                 keep `mat'*
 17.                                                 list if _n<=8
 18.                                                 save `folder'/`mat'_`final
> '_regular_ia, replace
 19.                                                 restore
 20.                         }       
 21.                         // shortstacked weights
.                         ddml extract, show(ssweights)
 22.                         foreach mat in Y_lnearn_ss D_gender_r_ss {
 23.                                         ddml extract, show(ssweights)
 24.                                         mat `mat' = r(`mat')
 25.                                         mat list `mat'
 26.                                                 preserve
 27.                                                 svmat `mat'
 28.                                                 keep `mat'*
 29.                                                 list if _n<=8
 30.                                                 save `folder'/`mat'_`final
> '_short_ia, replace
 31.                                                 restore
 32.                         }       
 33.                         // poolstacked weights
.                         ddml extract, show(psweights)
 34.                         foreach mat in Y_lnearn_ps D_gender_r_ps {
 35.                                         ddml extract, show(psweights)
 36.                                         mat `mat' = r(`mat')
 37.                                         mat list `mat'
 38.                                                 preserve
 39.                                                 svmat `mat'
 40.                                                 keep `mat'*
 41.                                                 list if _n<=8
 42.                                                 save `folder'/`mat'_`final
> '_pooled_ia, replace
 43.                                                 restore
 44.                         }       
 45.         
.         }
. 
.         forvalues i = 1(1)$L {
  2.                         ddml estimate, y1(Y1_pystacked1_L`i'_1) y0(Y1_pyst
> acked0_L`i'_1) ///
>                                                         d(D1_pystacked_L`i'_1
> ) robust atet foldvar(m0_sample_1  )
  3.                         regsave gender_r using `folder'/results.dta, ci //
> /
>                                                 addlabel(model,interactive,se
> ed,`seed',final,indiv,learner,`i') ///
>                                                 append
  4.         }
. 
. }       

.         
. *****************************************************************************
> *  
. *** interactive NX: short-stacking                                           
>                                       ***
. *****************************************************************************
> *
. 
. if (`estimator'==3) {
. 
. gen one = 1     
. 
.         cap drop y0base*
.         cap drop dbase*
.         cap drop y1base*
. 
.         *** no cross-fitting
.         pystacked lnearn $X_expanded   $pystring_reg0  if gender_r == 0, type
> (reg) njobs($cores)  
note: __000005 omitted because of collinearity
note: __00000D omitted because of collinearity
note: __00001Y omitted because of collinearity
note: __00001Z omitted because of collinearity
note: __000021 omitted because of collinearity
note: __000026 omitted because of collinearity
note: __000054 omitted because of collinearity
note: __00005C omitted because of collinearity
note: __00006P omitted because of collinearity
note: __00008C omitted because of collinearity
note: __00008I omitted because of collinearity

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0154028
  ols            |      0.0000000
  lassocv        |      0.1850465
  ridgecv        |      0.1560105
  lassocv        |      0.0000000
  ridgecv        |      0.0000000
  rf             |      0.5017506
  rf             |      0.0000000
  rf             |      0.0000000
  gradboost      |      0.0000000
  gradboost      |      0.1350082
  nnet           |      0.0000000
  nnet           |      0.0067814
.                 mat nxw_ia_y0 = e(weights)
.                 mat list nxw_ia_y0

nxw_ia_y0[13,1]
            c1
 r1   .0154028
 r2          0
 r3  .18504648
 r4  .15601055
 r5          0
 r6  8.397e-17
 r7  .50175062
 r8  4.552e-16
 r9          0
r10  4.135e-17
r11  .13500819
r12  1.870e-16
r13  .00678137
.                                 preserve
.                                 svmat nxw_ia_y0
.                                 keep nxw_ia_y0*
.                                 save `folder'/nxw_ia_y0, replace
(note: file out_53356/nxw_ia_y0.dta not found)
file out_53356/nxw_ia_y0.dta saved
.                                 restore
.         predict y0base0, xb
.         predict y0base, base
. 
.         pystacked lnearn $X_expanded  $pystring_reg0 if gender_r == 1  , type
> (reg) njobs($cores)  
note: __000005 omitted because of collinearity
note: __00000X omitted because of collinearity
note: __00000Y omitted because of collinearity
note: __00001X omitted because of collinearity
note: __00001Z omitted because of collinearity
note: __000020 omitted because of collinearity
note: __000025 omitted because of collinearity
note: __00002G omitted because of collinearity
note: __00003B omitted because of collinearity
note: __00005C omitted because of collinearity
note: __00006J omitted because of collinearity
note: __00007B omitted because of collinearity
note: __00007C omitted because of collinearity
note: __00008D omitted because of collinearity
note: __00008E omitted because of collinearity
note: __00008J omitted because of collinearity
note: __00008U omitted because of collinearity
note: __00009P omitted because of collinearity

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ols            |      0.0000000
  lassocv        |      0.0000000
  ridgecv        |      0.0000000
  lassocv        |      0.4183281
  ridgecv        |      0.0066226
  rf             |      0.3856641
  rf             |      0.0000000
  rf             |      0.0000000
  gradboost      |      0.0623187
  gradboost      |      0.0658760
  nnet           |      0.0000000
  nnet           |      0.0611906
.                 mat nxw_ia_y1 = e(weights)
.                 mat list nxw_ia_y1

nxw_ia_y1[13,1]
            c1
 r1  3.413e-16
 r2          0
 r3          0
 r4          0
 r5  .41832811
 r6  .00662256
 r7  .38566408
 r8  1.208e-16
 r9  3.216e-16
r10  .06231866
r11  .06587596
r12  6.590e-16
r13  .06119063
.                                 preserve
.                                 svmat nxw_ia_y1
.                                 keep nxw_ia_y1*
.                                 save `folder'/nxw_ia_y1, replace
(note: file out_53356/nxw_ia_y1.dta not found)
file out_53356/nxw_ia_y1.dta saved
.                                 restore
.         predict y1base0, xb
.         predict y1base, base
. 
.         pystacked gender_r $X_expanded $pystring_class  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.2572272
  logit          |      0.0000000
  lassocv        |      0.0000000
  ridgecv        |      0.1782287
  lassocv        |      0.0037785
  ridgecv        |      0.0000000
  rf             |      0.2742850
  rf             |      0.0000000
  rf             |      0.0000000
  gradboost      |      0.0000000
  gradboost      |      0.2825190
  nnet           |      0.0000000
  nnet           |      0.0039615
.                 mat nxw_ia_d = e(weights)
.                 mat list nxw_ia_d

nxw_ia_d[13,1]
            c1
 r1  .25722724
 r2          0
 r3          0
 r4  .17822873
 r5   .0037785
 r6          0
 r7  .27428501
 r8  1.451e-16
 r9  2.836e-16
r10  2.198e-17
r11  .28251902
r12  9.842e-17
r13   .0039615
.                                 preserve
.                                 svmat nxw_ia_d
.                                 keep nxw_ia_d*
.                                 save `folder'/nxw_ia_d, replace
(note: file out_53356/nxw_ia_d.dta not found)
file out_53356/nxw_ia_d.dta saved
.                                 restore         
.         predict dbase0, pr
.         predict dbase, base pr
.         
.         forvalues i = 0(1)$L {
  2.                         _estimate_ate interactive, yname(lnearn) dname(gen
> der_r) ///
>                                                 y0(y0base`i') y1(y1base`i') d
> (dbase`i') ///
>                                                 atet foldid(one) robust model
> (interactive)
  3.                         regsave gender_r using `folder'/results.dta, ///
>                                                 ci addlabel(model,nxinter,see
> d,`seed',final,nx,learner,`i') append
  4.         }

E[y|X,D=0]   = y0base0                             Number of obs   =      4836
E[y|X,D=1]   = y1base0
E[D|X]       = dbase0
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1042902   .0085365   -12.22   0.000    -.1210213    -.087559
------------------------------------------------------------------------------
Warning: 40 propensity scores trimmed to lower limit ..
Warning: 2 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base1                             Number of obs   =      4836
E[y|X,D=1]   = y1base1
E[D|X]       = dbase1
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1184321   .0198372    -5.97   0.000    -.1573123   -.0795519
------------------------------------------------------------------------------
Warning: 134 propensity scores trimmed to lower limit ..
Warning: 38 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base2                             Number of obs   =      4836
E[y|X,D=1]   = y1base2
E[D|X]       = dbase2
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1205585   .0157971    -7.63   0.000    -.1515203   -.0895967
------------------------------------------------------------------------------
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base3                             Number of obs   =      4836
E[y|X,D=1]   = y1base3
E[D|X]       = dbase3
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.0906687   .0205422    -4.41   0.000    -.1309307   -.0504067
------------------------------------------------------------------------------
Warning: 131 propensity scores trimmed to lower limit ..
Warning: 27 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base4                             Number of obs   =      4836
E[y|X,D=1]   = y1base4
E[D|X]       = dbase4
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.0927623   .0183454    -5.06   0.000    -.1287186    -.056806
------------------------------------------------------------------------------
Warning: 53 propensity scores trimmed to lower limit ..
Warning: 9 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base5                             Number of obs   =      4836
E[y|X,D=1]   = y1base5
E[D|X]       = dbase5
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.0963032   .0163767    -5.88   0.000    -.1284009   -.0642055
------------------------------------------------------------------------------
Warning: 44 propensity scores trimmed to lower limit ..
Warning: 3 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base6                             Number of obs   =      4836
E[y|X,D=1]   = y1base6
E[D|X]       = dbase6
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1030043   .0169547    -6.08   0.000    -.1362349   -.0697736
------------------------------------------------------------------------------
Warning: 91 propensity scores trimmed to lower limit ..
Warning: 20 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base7                             Number of obs   =      4836
E[y|X,D=1]   = y1base7
E[D|X]       = dbase7
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1164491   .0081084   -14.36   0.000    -.1323412    -.100557
------------------------------------------------------------------------------
Warning: 47 propensity scores trimmed to lower limit ..
Warning: 33 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base8                             Number of obs   =      4836
E[y|X,D=1]   = y1base8
E[D|X]       = dbase8
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1075752   .0142772    -7.53   0.000     -.135558   -.0795924
------------------------------------------------------------------------------
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base9                             Number of obs   =      4836
E[y|X,D=1]   = y1base9
E[D|X]       = dbase9
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1101979   .0144029    -7.65   0.000     -.138427   -.0819687
------------------------------------------------------------------------------
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base10                            Number of obs   =      4836
E[y|X,D=1]   = y1base10
E[D|X]       = dbase10
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.0899036   .0116728    -7.70   0.000    -.1127818   -.0670254
------------------------------------------------------------------------------
Warning: 1 propensity scores trimmed to lower limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base11                            Number of obs   =      4836
E[y|X,D=1]   = y1base11
E[D|X]       = dbase11
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |   -.098422   .0092714   -10.62   0.000    -.1165936   -.0802504
------------------------------------------------------------------------------
Warning: 95 propensity scores trimmed to lower limit ..
Warning: 24 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base12                            Number of obs   =      4836
E[y|X,D=1]   = y1base12
E[D|X]       = dbase12
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |    -.14166   .0142901    -9.91   0.000     -.169668    -.113652
------------------------------------------------------------------------------
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved

E[y|X,D=0]   = y0base13                            Number of obs   =      4836
E[y|X,D=1]   = y1base13
E[D|X]       = dbase13
------------------------------------------------------------------------------
             |               Robust
      lnearn |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    gender_r |  -.1548206   .0609085    -2.54   0.011     -.274199   -.0354422
------------------------------------------------------------------------------
Warning: 146 propensity scores trimmed to lower limit ..
Warning: 84 propensity scores trimmed to upper limit ..
(note: variable final was str2, now str10 to accommodate using data's values)
file out_53356/results.dta saved
.                 
. }

.         
. *****************************************************************************
> *  
. *** partial NX: short-stacking                                               
>                                       ***
. *****************************************************************************
> *
. 
. if (`estimator'==4) {
.         
. cap gen one = 1 
. 
.         cap drop Ybase* 
.         cap drop Dbase*
. 
.         *** no cross-fitting
.         pystacked lnearn $X_expanded $pystring_reg 
.                 mat nxw_y = e(weights)
.                 mat list nxw_y
.                                 preserve
.                                 svmat nxw_y
.                                 keep nxw_y*
.                                 save `folder'/nxw_y, replace
.                                 restore
.         predict Ybase0
.         predict Ybase, basexb
. 
.         pystacked gender_r $X_expanded $pystring_reg 
.                 mat nxw_d = e(weights)
.                 mat list nxw_d
.                                 preserve
.                                 svmat nxw_d
.                                 keep nxw_d*
.                                 save `folder'/nxw_d, replace
.                                 restore         
.         predict Dbase0
.         predict Dbase, basexb
. 
.         forvalues i = 0(1)$L {
  2.                 cap drop Ytil
  3.                 cap drop Dtil
  4.                 gen Ytil = lnearn - Ybase`i'
  5.                 gen Dtil = gender_r - Dbase`i'
  6.                 reg Ytil Dtil, robust
  7.                 regsave Dtil using `folder'/results.dta, ///
>                         ci addlabel(model,nxpartial,seed,`seed',final,nx,lear
> ner,`i') append
  8.         }
. 
. }

.         
. cap log close
